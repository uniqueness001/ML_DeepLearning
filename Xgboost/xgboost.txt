Boosting算法的基本思想：把成百上千个分类准确率较低的树模型集成起来，成为一个准确率很高的模型，这个模型不断迭代，每次迭代都会生成一个新的树；
Xgboost可以说是GBDT（梯度提升树）的进化版
Xgboost最大的特点：它能够自动利用CPU的多线程进行并行计算，同时算法也更加优化
三大特点：速度快，效果好，功能多
速度好：并行计算
效果好：对缺失值得处理可以自动学习出它分裂的方向
功能多：参数非常多
Xgboost的参数：
官方参数介绍看这里： 
Parameters (official guide)
http://xgboost.readthedocs.io/en/latest/parameter.html#general-parameters
General Parameters（常规参数） 
1.booster [default=gbtree]：选择基分类器，gbtree: tree-based models/gblinear: linear models 
2.silent [default=0]:设置成1则没有运行信息输出，最好是设置为0. 
3.nthread [default to maximum number of threads available if not set]：线程数

Booster Parameters（模型参数） 
1.eta [default=0.3]:shrinkage参数，用于更新叶子节点权重时，乘以该系数，避免步长过大。参数值越大，越可能无法收敛。把学习率 eta 设置的小一些，小学习率可以使得后面的学习更加仔细。 
2.min_child_weight [default=1]:这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 
3.max_depth [default=6]: 每颗树的最大深度，树高越深，越容易过拟合。 
4.max_leaf_nodes:最大叶结点数，与max_depth作用有点重合。 
5.gamma [default=0]：后剪枝时，用于控制是否后剪枝的参数。 
6.max_delta_step [default=0]：这个参数在更新步骤中起作用，如果取0表示没有约束，如果取正值则使得更新步骤更加保守。可以防止做太大的更新步子，使更新更加平缓。 
7.subsample [default=1]：样本随机采样，较低的值使得算法更加保守，防止过拟合，但是太小的值也会造成欠拟合。 
8.colsample_bytree [default=1]：列采样，对每棵树的生成用的特征进行列采样.一般设置为： 0.5-1 
9.lambda [default=1]：控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。 
10.alpha [default=0]:控制模型复杂程度的权重值的 L1 正则项参数，参数值越大，模型越不容易过拟合。 
11.scale_pos_weight [default=1]：如果取值大于0的话，在类别样本不平衡的情况下有助于快速收敛。

Learning Task Parameters（学习任务参数） 
1.objective [default=reg:linear]：定义最小化损失函数类型，常用参数： 
binary:logistic Clogistic regression for binary classification, returns predicted probability (not class) 
multi:softmax Cmulticlass classification using the softmax objective, returns predicted class (not probabilities) 
you also need to set an additional num_class (number of classes) parameter defining the number of unique classes 
multi:softprob Csame as softmax, but returns predicted probability of each data point belonging to each class. 

2.eval_metric [ default according to objective ]： 
The metric to be used for validation data. 
The default values are rmse for regression and error for classification. 
Typical values are: 
rmse C root mean square error 
mae C mean absolute error 
logloss C negative log-likelihood 
error C Binary classification error rate (0.5 threshold) 
merror C Multiclass classification error rate 
mlogloss C Multiclass logloss 
auc: Area under the curve 
3.seed [default=0]： 
The random number seed. 随机种子，用于产生可复现的结果 
Can be used for generating reproducible results and also for parameter tuning.
注意: python sklearn style参数名会有所变化 
eta C> learning_rate 
lambda C> reg_lambda 
alpha C> reg_alpha